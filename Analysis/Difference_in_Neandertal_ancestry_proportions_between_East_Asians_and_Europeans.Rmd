---
  title: "East Asians vs European NEA difference through time analysis"
output:
  html_document:
  keep_md: yes
pdf_document: default
---
  
  ```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# East Asians vs European NEA difference through time analysis

## Functions

```{r eval=T,echo=F,results='hide'}
source("~/EMH_Introgression_Project/Introgression_Detection/scripts/Analysis_R_functions.R")
```


## Cutoffs

```{r eval=T,echo=F,results='hide'}
chrom_ <- c("1" ,"2" , "3" , "4",  "5" , "6"  ,"7" , "8" , "9" , "10" ,"11", "12" ,"13","14" ,"15", "16" ,"17" ,"18", "19" , "20" ,"21", "22" )

cluster_used = "clusterF3D_broad"


genetic_map = "Shared_Map"

min_len_present = 0.05
min_bp_len_present = 0
min_len_ancient = 0.2
min_bp_len_ancient = 0
min_SNP = 0
min_all_SNP = 0
penalty = 0.25
states = c("NEA")
called_type = as.vector(c("state"))
```

## Meta Data

```{r eval=T,echo=F,results='hide'}
THEME <-  theme_bw() + theme(axis.title=element_text(face="bold"))


folder_path = "~/EMH_Introgression_Project/Introgression_Detection/Paper_Figures/"

folder_path_Sup_Tables = "~/EMH_Introgression_Project/Introgression_Detection/Supplements_Tables/"

Joint_Meta_all <- read.csv("~/EMH_Introgression_Project/Introgression_Detection/Joint_Meta_data_genetic_clusters_using_1240k.csv") %>% 
  mutate(sample_name=gsub( "-", ".", sample_name))  %>% mutate(Data_Set = ifelse(ML_BP_Mean == 0,"SGDP","ancient"))

Joint_Meta <- read.csv("~/EMH_Introgression_Project/Introgression_Detection/Joint_Meta_data_genetic_clusters_using_1240k.csv") %>% 
  mutate(sample_name=gsub( "-", ".", sample_name)) %>%
  filter(sample_name != "Mota",SuperclusterF3D != "Africa") %>% mutate(Data_Set = ifelse(ML_BP_Mean == 0,"SGDP","ancient"))

Meta_1kGenomes <- read.csv("/mnt/diversity/leonardo_iasi/EMH_Introgression_Project/New_REF_AA_with_APX_1kGnonAfr_admixfrog0.7_Shared_Map/stats/gtmode/AFR-NEA-DEN/Shared_Map/QC_All1kGphaseIIInonAfricans_length_bin_15_5000_archaicadmixtureAPX.wide_updated.csv") %>%
  mutate(Cov = 3,Data_Set = "G1k") 

G1k_to_paper_pops <- read.csv("~/EMH_Introgression_Project/Introgression_Detection/G1k_to_paper_clusters.csv") 
G1k_to_paper_pops$G1k_pop[G1k_to_paper_pops$G1k_pop == "GHI"] <- "GIH"

Meta_1kGenomes <- inner_join(Meta_1kGenomes,G1k_to_paper_pops,by=c("pop"="G1k_pop")) 

Prop_callable <- read.table("/mnt/diversity/leonardo_iasi/EMH_Introgression_Project/New_REF_AA_with_APX_1kGnonAfr_admixfrog0.7_Shared_Map/stats/gtmode/length_bin_15/Shared_Map/AFR-NEA-DEN_All1kGphaseIIInonAfricans_5000_archaicadmixtureAPX_1.proportion_callable_genome.txt")

Meta_1kGenomes <- inner_join(Meta_1kGenomes,Prop_callable,by=c("sample_name"="V1")) %>%
  dplyr::rename(prop_callable = V2)


Cov_1KG_autosomes = read.table("/mnt/diversity/leonardo_iasi/EMH_Introgression_Project/New_REF_AA_with_APX_1kGnonAfr_admixfrog0.7_Shared_Map/stats/Sample_coverage_All1kGphaseIIInonAfricans_length_bin_15_archaicadmixtureAPX.cov.autosomes.txt",header = T)
colnames(Cov_1KG_autosomes) <- c("sample_name", "ave_cov_autosomes"   ,  "median_cov_autosomes" , "n_sites_cov_autosomes")

Meta_1kGenomes <- inner_join(Meta_1kGenomes,Cov_1KG_autosomes,by="sample_name")

common_cols <- intersect(colnames(Joint_Meta), colnames(Meta_1kGenomes))

All_Joint_Meta <- rbind(
  subset(Joint_Meta, select = common_cols), 
  subset(Meta_1kGenomes, select = common_cols)
)

All_Joint_Meta$prop_callable <- as.numeric(All_Joint_Meta$prop_callable)

Joint_Meta_unrelated <- Joint_Meta %>% filter(sample_name %notin% c("AfanasievoSon1","AfanasievoSon2"))


common_cols <- intersect(colnames(Joint_Meta_unrelated), colnames(Meta_1kGenomes))

All_Joint_Meta_unrelated <- rbind(
  subset(Joint_Meta_unrelated, select = common_cols), 
  subset(Meta_1kGenomes, select = common_cols)
)

All_Joint_Meta_unrelated$prop_callable <- as.numeric(All_Joint_Meta_unrelated$prop_callable)

All_Joint_Meta_unrelated_no_ancients_in_SGDP <- All_Joint_Meta_unrelated

X_chrom_captured <- Joint_Meta %>% filter(Data_source %in% c("Genotypes","Shotgun")) 
X_chrom_captured_femal_only <- Joint_Meta %>% filter(Data_source %in% c("Genotypes","Shotgun"), Sex %in% c("female","F")) 

cluster_color_broad_all = data.frame(clusterF3D_broad_all = c("AncientEAS","ANE","ANS","EarlyOoA","EAS","North_Africa","Oceania","postLGM-WEurHG","preLGM-WEurHG","SA","Satsurblia","Siberia&Americas" ,"Sub-Sahara-Africa","SWA","WEur","Yamnaya"),
                                     cluster_color = 
                                       c("#009292FF","#FFCC00","#6DB6FFFF","#004949FF","#924900FF","#808080","#006DDBFF","#490092FF","#DB6D00FF","#920000FF","#FFB6DBFF","#24FF24FF","#000000FF","#B66DFFFF","#FF6DB6FF","#B6DBFFFF"))

cluster_color_broad = data.frame(clusterF3D_broad = c("AncientEAS","ANE","ANS","EarlyOoA","EAS","Oceania","postLGM-WEurHG","preLGM-WEurHG","SA","Satsurblia","Siberia&Americas" ,"SWA","WEur","Yamnaya"),
                                 cluster_color = 
                                   c("#009292FF","#FFCC00","#6DB6FFFF","#004949FF","#924900FF","#006DDBFF","#490092FF","#DB6D00FF","#920000FF","#FFB6DBFF","#24FF24FF","#B66DFFFF","#FF6DB6FF","#B6DBFFFF"))


Supercluster_color = data.frame(SuperclusterF3D = c("Americas&Asia","EarlyOoA","Oceania","WEurCAS"),Supercluster_color = c("#924900FF","#004949FF","#006DDBFF","#FF6DB6FF"))

chrom_ <- c("1" ,"2" , "3" , "4",  "5" , "6"  ,"7" , "8" , "9" , "10" ,"11", "12" ,"13","14" ,"15", "16" ,"17" ,"18", "19" , "20" ,"21", "22" )

THEME <-  theme_bw() + theme(axis.title=element_text(face="bold"))

cluster_used = "clusterF3D_broad"

cluster_color = cluster_color_broad

cluster_order <- Joint_Meta %>% dplyr::select((!!sym(cluster_used)),ML_BP_Mean) %>%
  group_by((!!sym(cluster_used))) %>% dplyr::summarize(mean_age = mean(ML_BP_Mean),n_inds = n()) %>%
  ungroup() %>%
  mutate(cluster_wraped = gsub( "&", "\n and ", (!!sym(cluster_used))),cluster_wraped = gsub( "-", "\n", (!!sym(cluster_used))))

cluster_order <- cluster_order[with(cluster_order, order(mean_age,decreasing = T)), ]

cluster_order_all <- Joint_Meta_all %>% dplyr::select((!!sym(cluster_used)),ML_BP_Mean) %>%
  group_by((!!sym(cluster_used))) %>% dplyr::summarize(mean_age = mean(ML_BP_Mean),n_inds = n()) %>%
  ungroup() %>%
  mutate(cluster_wraped = gsub( "&", "\n and ", (!!sym(cluster_used))),cluster_wraped = gsub( "-", "\n", (!!sym(cluster_used))))

cluster_order_all <- cluster_order_all[with(cluster_order_all, order(mean_age,decreasing = T)), ]

genetic_map = "Shared_Map"

gen_time = 28

min_len_present = 0.05
min_bp_len_present = 0
min_len_ancient = 0.2
min_bp_len_ancient = 0
min_SNP = 0
min_all_SNP = 0
penalty = 0.25
states = c("NEA")
called_type = as.vector(c("state"))

```

## Ancestry proportions

### overall data

```{r eval=T,echo=F,results='hide'}
All_Pops_NEA_props <- Joint_Meta_all %>% 
  dplyr::select(clusterF3D_broad,ML_BP_Mean,sample_name,estimate_all_f4r_NEA,estimate_all_f4r_NEA_1240k,estimate_all_admixfrog_NEA,Data_Set) %>%
  pivot_longer(!c(clusterF3D_broad,ML_BP_Mean,sample_name,Data_Set), names_to = "method", values_to = "est") %>%
  mutate(cluster_ordered = gsub( "&", "\n and ", (!!sym(cluster_used))),cluster_ordered = gsub( "-", "\n", (!!sym(cluster_used)))) %>%
  mutate(cluster_ordered = factor(cluster_ordered, levels=cluster_order_all$cluster_wraped)) %>% dplyr::select(!clusterF3D_broad)


G1k_Pops_NEA_props <- Meta_1kGenomes %>% mutate(estimate_all_f4r_NEA_1240k = NA) %>%
  dplyr::select(clusterF3D_broad,sample_name,estimate_all_f4r_NEA,estimate_all_admixfrog_NEA,estimate_all_f4r_NEA_1240k,Data_Set) %>%
  pivot_longer(!c(clusterF3D_broad,sample_name,Data_Set), names_to = "method", values_to = "est") %>% 
  mutate(ML_BP_Mean = 0) %>% dplyr::rename(cluster_ordered = clusterF3D_broad) %>%
  mutate(cluster_ordered = factor(cluster_ordered, levels=cluster_order$cluster_wraped))

All_Pops_NEA_props <- rbind(All_Pops_NEA_props,G1k_Pops_NEA_props)

All_Pops_NEA_props_long <- All_Pops_NEA_props %>% mutate(Data_Set2 = "All")
All_Pops_NEA_props_long <- All_Pops_NEA_props %>% 
  filter(Data_Set != "SGDP") %>% mutate(Data_Set2 = "Ancient + 1kG") %>% rbind(.,All_Pops_NEA_props_long)
All_Pops_NEA_props_long <- All_Pops_NEA_props %>% 
  filter(Data_Set != "G1k") %>% mutate(Data_Set2 = "Ancient + SGDP") %>% rbind(.,All_Pops_NEA_props_long)


WEur_inds <- All_Pops_NEA_props %>% filter(cluster_ordered == "WEur", Data_Set == "SGDP",ML_BP_Mean == 0) %>%
  mutate(cluster_ordered = paste0(cluster_ordered," (SGDP)"))

EAS_inds <- All_Pops_NEA_props %>% filter(cluster_ordered == "EAS", Data_Set == "SGDP", ML_BP_Mean == 0) %>%
  mutate(cluster_ordered = paste0(cluster_ordered," (SGDP)"))

EUR_1kG_inds <- All_Pops_NEA_props %>% filter(cluster_ordered == "WEur", Data_Set == "G1k", ML_BP_Mean == 0) %>%
  mutate(cluster_ordered = paste0(cluster_ordered," (1kG)"))

EAS_1kG_inds <- All_Pops_NEA_props %>% filter(cluster_ordered == "EAS", Data_Set == "G1k", ML_BP_Mean == 0) %>%
  mutate(cluster_ordered = paste0(cluster_ordered," (1kG)"))

ancientEAS_inds <- All_Pops_NEA_props %>% filter(cluster_ordered == "AncientEAS")

ancientEUR_inds <- All_Pops_NEA_props %>% filter(cluster_ordered == "preLGM\nWEurHG")

EAS_vs_EURO <- rbind(WEur_inds,EAS_inds,EUR_1kG_inds,EAS_1kG_inds,ancientEAS_inds,ancientEUR_inds)

Prop_est_all <- EAS_vs_EURO %>%
  mutate(cluster_ordered = factor(cluster_ordered))
Prop_est_all$cluster_ordered <- factor(Prop_est_all$cluster_ordered, levels=c('AncientEAS', 'preLGM\nWEurHG', 'EAS (SGDP)', "EAS (1kG)","WEur (SGDP)","WEur (1kG)"))


P_present_vs_ancient_EUR_EAS <- Prop_est_all %>%
  filter(method != "estimate_all_f4r_NEA_1240k") %>%
  ggplot(data = .,aes(x=cluster_ordered,y=est)) +
  facet_grid(~method) +
  geom_boxplot()  + 
  THEME +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  xlab("") +
  ylab("Proportion Neandertal ancestry")

ggsave(paste0(folder_path_save,"P_present_vs_ancient_EUR_EAS.png"),P_present_vs_ancient_EUR_EAS,device = "png",width = 8,height = 5)

```

### check power

```{r eval=T,echo=F,results='hide'}
### difference between a randomly sampled EAS and EUR 

est_method = c("estimate_all_f4r_NEA","estimate_all_admixfrog_NEA")
n_rep = 500
Prop_est_sample_list <- list()
Diff_list <- list()
for(i in 1:length(est_method)){
  
  EAS_vs_EURO_random <- EAS_vs_EURO %>% group_by(cluster_ordered) %>% filter(method == !!est_method[i]) %>%
    sample_n(n_rep,replace = T) 
  
  Diff_ancient <- data.frame(diff = EAS_vs_EURO_random$est[EAS_vs_EURO_random$cluster_ordered == "AncientEAS"] - EAS_vs_EURO_random$est[EAS_vs_EURO_random$cluster_ordered == "preLGM\nWEurHG"],
                             pop = "AncientEAS vs preLGM-WEurHG",method = est_method[i],AncientEASsample = EAS_vs_EURO_random$sample_name[EAS_vs_EURO_random$cluster_ordered == "AncientEAS"],
                             AncientWEursample = EAS_vs_EURO_random$sample_name[EAS_vs_EURO_random$cluster_ordered == "preLGM\nWEurHG"])
  
  Diff_present_SGDP <- data.frame(diff = EAS_vs_EURO_random$est[EAS_vs_EURO_random$cluster_ordered == "EAS (SGDP)"] - EAS_vs_EURO_random$est[EAS_vs_EURO_random$cluster_ordered == "WEur (SGDP)"],
                                  pop = "EAS vs WEur (SGDP)",method = est_method[i],AncientEASsample = "other",AncientWEursample = "other" )
  
  Diff_present_1kG <- data.frame(diff = EAS_vs_EURO_random$est[EAS_vs_EURO_random$cluster_ordered == "EAS (1kG)"] - EAS_vs_EURO_random$est[EAS_vs_EURO_random$cluster_ordered == "WEur (1kG)"],
                                 pop = "EAS vs WEur (1kG)",method = est_method[i],AncientEASsample = "other",AncientWEursample = "other" )
  
  Diff_list[[i]] <- rbind(Diff_ancient,Diff_present_SGDP,Diff_present_1kG)
  
  
  
}
Diff_prop <- do.call('rbind',Diff_list)


P_random_pairwise_diff_present_vs_ancient_EUR_EAS <- 
  ggplot(data = Diff_prop,aes(x=pop,y=diff,col=pop,shape=AncientEASsample)) +
  facet_grid(~method) +
  geom_jitter() +
  xlab("") +
  ylab("More Neandertal ancestry in\n WEur <-> EAS") +
  geom_hline(yintercept = 0) +
  THEME +
  theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ggtitle("Pairwise")

Diff_prop_distinct <- Diff_prop %>% distinct()

P_random_pairwise_diff_present_vs_ancient_EUR_EAS_distinct <- 
  ggplot(data = Diff_prop_distinct,aes(x=pop,y=diff,col=pop,shape=AncientEASsample)) +
  facet_grid(~method) +
  geom_jitter() +
  xlab("") +
  ylab("More Neandertal ancestry in\n WEur <-> EAS") +
  geom_hline(yintercept = 0) +
  THEME +
  theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ggtitle("Pairwise")


### difference between mean of two randomly sampled EAS and EUR 

est_method = c("estimate_all_f4r_NEA","estimate_all_admixfrog_NEA")
Prop_est_sample_list <- list()
Diff_mean_list <- list()
for(i in 1:length(est_method)){
  
  EAS_vs_EURO_random <- EAS_vs_EURO %>% filter(method == !!est_method[i]) 
  
  sample_x = t(replicate(n= 10000,sample(EAS_vs_EURO_random$est[EAS_vs_EURO_random$cluster_ordered == "AncientEAS"],size = 2,replace = T)))
  sample_y = t(replicate(n= 10000,sample(EAS_vs_EURO_random$est[EAS_vs_EURO_random$cluster_ordered == "preLGM\nWEurHG"],size = 2,replace = T)))
  sample_set = as.data.frame(cbind(sample_x,sample_y)) %>% distinct()
  
  Diff_ancient <- data.frame(diff = (rowMeans(sample_set[,1:2]) - rowMeans(sample_set[,3:4])),
                             pop = "AncientEAS vs preLGM-WEurHG",method = est_method[i],AncientEASsample = "other")
  
  sample_x = t(replicate(n= 500,sample(EAS_vs_EURO_random$est[EAS_vs_EURO_random$cluster_ordered == "EAS (SGDP)"],size = 2,replace = T)))
  sample_y = t(replicate(n= 500,sample(EAS_vs_EURO_random$est[EAS_vs_EURO_random$cluster_ordered == "WEur (SGDP)"],size = 2,replace = T)))
  sample_set = as.data.frame(cbind(sample_x,sample_y)) %>% distinct()
  
  Diff_present_SGDP <- data.frame(diff = (rowMeans(sample_set[,1:2]) - rowMeans(sample_set[,3:4])),
                                  pop = "EAS vs WEur (SGDP)",method = est_method[i],AncientEASsample = "other" )
  
  sample_x = t(replicate(n= 500,sample(EAS_vs_EURO_random$est[EAS_vs_EURO_random$cluster_ordered == "EAS (1kG)"],size = 2,replace = T)))
  sample_y = t(replicate(n= 500,sample(EAS_vs_EURO_random$est[EAS_vs_EURO_random$cluster_ordered == "WEur (1kG)"],size = 2,replace = T)))
  sample_set = as.data.frame(cbind(sample_x,sample_y)) %>% distinct()
  
  Diff_present_1kG <- data.frame(diff = (rowMeans(sample_set[,1:2]) - rowMeans(sample_set[,3:4])),
                                 pop = "EAS vs WEur (1kG)",method = est_method[i],AncientEASsample = "other")
  
  Diff_mean_list[[i]] <- rbind(Diff_ancient,Diff_present_SGDP,Diff_present_1kG)
  
  
  
}
Diff_mean_prop <- do.call('rbind',Diff_mean_list)

P_random_mean_diff_present_vs_ancient_EUR_EAS <- 
  ggplot(data = Diff_mean_prop,aes(x=pop,y=diff,col=pop,shape=AncientEASsample)) +
  facet_grid(~method) +
  geom_jitter() +
  xlab("") +
  ylab("More Neandertal ancestry in\n WEur <-> EAS") +
  geom_hline(yintercept = 0) +
  THEME +
  theme(legend.position = "none") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  ggtitle("Mean of two individuals")
P_random_mean_diff_present_vs_ancient_EUR_EAS

P_random_mean_present_vs_ancient_EUR_EAS <- ggpubr::ggarrange(P_random_pairwise_diff_present_vs_ancient_EUR_EAS_distinct,
                                                              P_random_mean_diff_present_vs_ancient_EUR_EAS,ncol = 2)


```


## One vs Two Pulse dating in Tianyuan and Salkhit

### Power Analysis

```{r eval=T,echo=F,results='hide'}
sample_simple_pulse_ACov_sim <- function(min_dist,max_dist,binwidth,A,tm,c=0,noise=0.001,round_dec=0.01){
  dist= seq(min_dist,max_dist,binwidth)
  wcov = A*exp(-(dist)*(tm))+c
  wcov_n = wcov + rnorm(length(wcov),mean = 0,sd = noise)
  data.x = data.frame(dist=dist,wcov=wcov_n)
  return(data.x)
}

sample_simple_pulse_Seg_sim <- function(n_seg,tm,noise){
  data.x = rexp(n_seg,rate = (tm ))
  data.x_n = data.x + rnorm(length(data.x),mean = 0,sd = noise/100)
  return(data.x_n)
}

sample_two_pulse_ACov_sim <- function(min_dist,max_dist,binwidth,A1,A2,tm1,tm2,c=0,noise=0.001){
  dist= seq(min_dist,max_dist,binwidth)
  wcov = c + A1*exp(-dist*(tm1)) + A2*exp(-dist*(tm2))
  wcov_n = wcov + rnorm(length(wcov),mean = 0,sd = noise)
  data.x = data.frame(dist=dist,wcov=wcov_n) 
  return(data.x)
}

sample_two_pulse_Seg_sim <- function(n_seg,tm1,tm2,alpha1,alpha2,noise){
  data.x =   c(rexp(round(n_seg * alpha1),rate = tm1),rexp(round(n_seg*alpha2),rate = tm2))
  data.x_n = data.x + rnorm(length(data.x),mean = 0,sd = noise/100)
  return(data.x_n)
}

fit_ACov_sim <- function(ind,dist,y,A_init=0.01,C_init=0.02,tm_init=200,A1_init=0.01,A2_init=0.02,tm1_init=100,tm2_init=200){
  
  ## SP fit
  fm1 <- function(x) x[3] + x[1]*exp(-x[2] * dist)
  fm2 <- function(x) sum((y-fm1(x))^2)
  fm3 <- DEoptim(fm2, lower=c(0.0001,1,0.0001), upper=c(10,1000,10e7), control=list(trace=FALSE))
  par1 <- fm3$optim$bestmem
  
  # parameters for y ~ Ae-mt + C
  names(par1) <- c("A","tm","C")
  
  # fit the model of Single exponential
  res_fit <- nls(y ~ fnx_SP_singlefit(A,tm,C,0,dist), start=par1,algorithm="port",
                 lower=c(0,1,-1), upper=c(1,2000,1),
                 control=list(warnOnly=TRUE))
  
  
  RSS = sum((y - fnx_SP_singlefit(coef(res_fit)[1],coef(res_fit)[2],coef(res_fit)[3],0,dist))^2)
  n_DP = length(dist)
  LL_SP = - n_DP/2 * log(RSS) - n_DP/2 * log(2*pi / n_DP) - n_DP/2
  
  res_df_SP = data.frame(ind = ind,tm_SP = coef(res_fit)[2], A_SP = coef(res_fit)[1], C_SP = coef(res_fit)[3],n_data = length(dist),LL_SP = LL_SP)
  
  ## TP fit
  
  fm1 <- function(x) x[5] + (x[1]*exp(-x[3] * dist) + x[2]*exp(-x[4] * dist))
  fm2 <- function(x) sum((y-fm1(x))^2)
  fm3 <- DEoptim(fm2, lower=c(0.1,0.0001,1,1,0.0001), upper=c(10,10,2000,2000,10e7), control=list(trace=FALSE))
  par1 <- fm3$optim$bestmem
  
  # parameters for y ~ Ae-mt + C
  names(par1) <- c("A1","A2","tm1","tm2","C")
  
  res_fit <- nls(y ~ fnx_TP_singlefit(A1,A2,tm1,tm2,C,0,dist), start=par1, algorithm="port",
                 lower=c(0,0,1,1,-1), upper=c(1,1,2000,2000,1),
                 control=list(warnOnly=TRUE))
  
  
  RSS = sum((y - fnx_TP_singlefit(coef(res_fit)[1],coef(res_fit)[2],coef(res_fit)[3],coef(res_fit)[4],coef(res_fit)[5],0,dist))^2)
  LL_TP = - n_DP/2 * log(RSS) - n_DP/2 * log(2*pi / n_DP) - n_DP/2
  
  res_df_TP = data.frame(A1_TP= coef(res_fit)[1],A2_TP= coef(res_fit)[2],tm1_TP=coef(res_fit)[3],tm2_TP=coef(res_fit)[4],C_TP= coef(res_fit)[5],LL_TP=LL_TP,covergence_TP= res_fit$convInfo$isConv)
  
  res_df <- cbind(res_df_SP,res_df_TP)
  
  return(res_df)
}

Two_pulses_EM_SS <- function(data,alpha1_hat,alpha2_hat,t1_hat,t2_hat,num_iterations=100){
  
  for (iteration in 1:num_iterations) {
    # E-step: Calculate the probabilities given the parameters
    p1 <- (alpha1_hat * dexp(data, t1_hat)) / ((alpha1_hat * dexp(data, t1_hat )) + (alpha2_hat * dexp(data, t2_hat)))
    p1 <- p1[!is.na(p1)]
    p2 <- 1 - p1
    
    # M-step: Update parameters
    alpha1_hat <- mean(p1)
    alpha2_hat <- mean(p2)
    t1_hat <- 1/ (sum(p1 * data) / sum(p1))
    t2_hat <- 1/ (sum(p2 * data) / sum(p2))
    
    # Print the parameter estimates for this iteration
    cat("Iteration", iteration, ": alpha1 =", alpha1_hat, "alpha2 =", alpha2_hat, "t1 =", t1_hat, "t2 =", t2_hat, "\n")
  }
  
  Lh <- (alpha1_hat * dexp(data, t1_hat ,log = F)) + (alpha2_hat * dexp(data, t2_hat,log = F))
  LL = sum( log( Lh[Lh > 0] ) )
  return(c(alpha1_hat,alpha2_hat,t1_hat,t2_hat,LL))
}

fit_Seg_sim <- function(ind,l,alpha1_hat,t1_hat,alpha2_hat,t2_hat,minlen=0){
  
  l = l - minlen
  
  res_SS_TP <- Two_pulses_EM_SS(l,alpha1_hat,alpha2_hat,t1_hat,t2_hat,num_iterations=500)
  
  tm_SP = 1/mean(l)
  LL_SP = sum(log(dexp(l, tm_SP,log = F)[dexp(l, tm_SP,log = F) > 0]))
  
  res_df <- data.frame(sample = ind,
                       tm1_TP = res_SS_TP[3],
                       tm2_TP = res_SS_TP[4],
                       alpha1_TP = res_SS_TP[1],
                       alpha2_TP = res_SS_TP[2],
                       n_data = length(l),
                       tm_SP = tm_SP,
                       LL_TP = res_SS_TP[5],
                       LL_SP = LL_SP)
  return(res_df)
}


### Sim Parameter

tm_Tianyuan = 321

tm1_Tianyuan = tm_Tianyuan  

tm2_Tianyuan = 70

n_segs_Tianyuan = nrow(read.csv("/mnt/diversity/leonardo_iasi/EMH_Introgression_Project/New_REF_AA_with_APX_EMH_admixfrog0.7_Shared_Map/rle/error2/length_bin_15/5000/AFR-NEA-DEN/Shared_Map/Tianyuan_archaicadmixtureAPX.rle0.25.xz") %>%
                         filter(type == "state", target == "NEA"))

tm_Salkhit = 459

tm1_Salkhit = tm_Salkhit 

tm2_Salkhit = 200



n_segs_Salkhit = nrow(read.csv("/mnt/diversity/leonardo_iasi/EMH_Introgression_Project/New_REF_AA_with_APX_EMH_admixfrog0.7_Shared_Map/rle/error2/length_bin_15/5000/AFR-NEA-DEN/Shared_Map/SalkhitArchAdm_archaicadmixtureAPX.rle0.25.xz") %>%
                        filter(type == "state", target == "NEA"))


### Sim one Pulse ###

process_ind_noise_pair_SP_sim <- function(ind, noise){
  library(DEoptim)
  res_SP_sim_Seg_list <- list()
  res_SP_sim_ACov_list <- list()
  for(rep in 1:100){
    
    if(ind == "Tianyuan"){
      sim_SP_ACov = sample_simple_pulse_ACov_sim(min_dist=0,max_dist=0.1,binwidth=0.00005,A=runif(1,0.02,0.04),tm_Tianyuan,c=0,noise=noise)
    }
    if(ind == "Salkhit"){
      sim_SP_ACov = sample_simple_pulse_ACov_sim(min_dist=0,max_dist=0.1,binwidth=0.00005,A=runif(1,0.02,0.04),tm_Salkhit,c=0,noise=noise)
    }
    
    
    Fit_ACov_res <- fit_ACov_sim(ind = ind,dist = sim_SP_ACov$dist,y = sim_SP_ACov$wcov)  
    
    Fit_ACov_res <- Fit_ACov_res %>%
      mutate(LRT = -2 *((LL_SP - LL_TP))) %>%
      mutate(p  = 1 - pchisq(LRT, 5 - 3),noise = noise,rep=rep) 
    
    
    ## Seg
    
    if(ind == "Tianyuan"){
      sim_SP_Seg <- sample_simple_pulse_Seg_sim(n_seg = n_segs_Tianyuan,tm = tm_Tianyuan,noise = noise)
    }
    if(ind == "Salkhit"){
      sim_SP_Seg <- sample_simple_pulse_Seg_sim(n_seg = n_segs_Salkhit,tm = tm_Salkhit,noise = noise)
    }
    
    Fit_Seg_res <- fit_Seg_sim(ind = ind,l = sim_SP_Seg,alpha1_hat = 0.5,alpha2_hat = 0.5,t1_hat = 100,t2_hat = 200,minlen = 0)
    
    Fit_Seg_res <- Fit_Seg_res %>%
      mutate(LRT = -2 *((LL_SP - LL_TP))) %>%
      mutate(p  = 1 - pchisq(LRT, 3 - 1),noise = noise,rep=rep) 
    
    # Append the results for this rep to the lists
    res_SP_sim_ACov_list[[rep]] <- Fit_ACov_res
    res_SP_sim_Seg_list[[rep]] <- Fit_Seg_res
  }
  
  res_SP_sim_ACov <- do.call('rbind',res_SP_sim_ACov_list)
  res_SP_sim_Seg <- do.call('rbind',res_SP_sim_Seg_list)
  
  # Return a list of the results for all reps for this pair of ind and noise values
  return(list(Seg = res_SP_sim_Seg, ACov = res_SP_sim_ACov))
}


param_grid <- expand.grid(ind = c("Tianyuan","Salkhit"), noise = c(0.001,0.002,0.004))
no_cores <- parallel::detectCores() - 1  
cl <- parallel::makeCluster(no_cores)
doParallel::registerDoParallel(cl)
result_list <- foreach(i = 1:nrow(param_grid), .packages = c('dplyr'), .combine='c') %dopar% {
  process_ind_noise_pair_SP_sim(param_grid$ind[i], param_grid$noise[i])
}
parallel::stopCluster(cl)


Seg_SP_res <- do.call(rbind, result_list[seq(1, length(result_list), 2)])
ACov_SP_res <- do.call(rbind, result_list[seq(2, length(result_list), 2)])

write.csv(Seg_SP_res,"~/EMH_Introgression_Project/Introgression_Detection/Revisions/Power_analysis_TP_SP_seg_sim.csv",quote = F,row.names = F)
write.csv(ACov_SP_res,"~/EMH_Introgression_Project/Introgression_Detection/Revisions/Power_analysis_TP_SP_ACov_sim.csv",quote = F,row.names = F)


### Sim Two Pulses ###



process_ind_noise_pair_TP_sim <- function(ind, noise, alpha_){
  library(DEoptim)
  res_TP_sim_Seg_list <- list()
  res_TP_sim_ACov_list <- list()
  for(rep in 1:100){
    print(alpha_)
    A = runif(1,0.02,0.04)
    if(ind == "Tianyuan"){
      sim_TP_ACov = sample_two_pulse_ACov_sim(min_dist=0,max_dist=0.1,binwidth=0.00005,A1 = A * alpha_,A2 = A * (1 - alpha_),tm1 = tm1_Tianyuan,tm2 = tm2_Tianyuan,c=0,noise=noise)
    }
    if(ind == "Salkhit"){
      sim_TP_ACov = sample_two_pulse_ACov_sim(min_dist=0,max_dist=0.1,binwidth=0.00005,A1 = A * alpha_,A2 = A * (1 - alpha_),tm1 = tm1_Salkhit,tm2 = tm2_Salkhit,c=0,noise=noise)
    }
    
    
    Fit_ACov_res <- fit_ACov_sim(ind = ind,dist = sim_TP_ACov$dist,y = sim_TP_ACov$wcov)  
    
    Fit_ACov_res <- Fit_ACov_res %>%
      mutate(LRT = -2 *((LL_SP - LL_TP))) %>%
      mutate(p  = 1 - pchisq(LRT, 5 - 3),noise = noise,rep=rep,alpha=alpha_) 
    
    
    ## Seg
    
    if(ind == "Tianyuan"){
      sim_TP_Seg <- sample_two_pulse_Seg_sim(n_seg = n_segs_Tianyuan,tm1 = tm1_Tianyuan,tm2 = tm2_Tianyuan,alpha1 = alpha_,alpha2 = (1-alpha_),noise = noise)
    }
    if(ind == "Salkhit"){
      sim_TP_Seg <- sample_two_pulse_Seg_sim(n_seg = n_segs_Salkhit,tm1 = tm1_Salkhit,tm2 = tm2_Salkhit,alpha1 = alpha_,alpha2 = (1-alpha_),noise = noise)
    }
    
    Fit_Seg_res <- fit_Seg_sim(ind = ind,l = sim_TP_Seg,alpha1_hat = 0.2,alpha2_hat = 0.8,t1_hat = 1,t2_hat = 2,minlen = 0)
    
    Fit_Seg_res <- Fit_Seg_res %>%
      mutate(LRT = -2 *((LL_SP - LL_TP))) %>%
      mutate(p  = 1 - pchisq(LRT, 3 - 1),noise = noise,rep=rep,alpha=alpha_) 
    
    # Append the results for this rep to the lists
    res_TP_sim_ACov_list[[rep]] <- Fit_ACov_res
    res_TP_sim_Seg_list[[rep]] <- Fit_Seg_res
  }
  
  res_TP_sim_ACov <- do.call('rbind',res_TP_sim_ACov_list)
  res_TP_sim_Seg <- do.call('rbind',res_TP_sim_Seg_list)
  
  # Return a list of the results for all reps for this pair of ind and noise values
  return(list(Seg = res_TP_sim_Seg, ACov = res_TP_sim_ACov))
}

param_grid <- expand.grid(ind = c("Tianyuan","Salkhit"), noise = c(0.001,0.002,0.004),alpha_ = c(0.5,0.25,0.1,0.05))
no_cores <- parallel::detectCores() - 1  
cl <- parallel::makeCluster(no_cores)
doParallel::registerDoParallel(cl)
result_list <- foreach(i = 1:nrow(param_grid), .packages = c('dplyr'), .combine='c') %dopar% {
  process_ind_noise_pair_TP_sim(param_grid$ind[i], param_grid$noise[i], param_grid$alpha_[i])
}
parallel::stopCluster(cl)

Seg_TP_res <- do.call(rbind, result_list[seq(1, length(result_list), 2)])
ACov_TP_res <- do.call(rbind, result_list[seq(2, length(result_list), 2)])

write.csv(Seg_TP_res,"~/EMH_Introgression_Project/Introgression_Detection/Revisions/Power_analysis_TP_TP_seg_sim.csv",quote = F,row.names = F)
write.csv(ACov_TP_res,"~/EMH_Introgression_Project/Introgression_Detection/Revisions/Power_analysis_TP_TP_ACov_sim.csv",quote = F,row.names = F)



## Plot res

Seg_SP_res <- read.csv("~/EMH_Introgression_Project/Introgression_Detection/Revisions/Power_analysis_TP_SP_seg_sim.csv")
ACov_SP_res <- read.csv("~/EMH_Introgression_Project/Introgression_Detection/Revisions/Power_analysis_TP_SP_ACov_sim.csv")

Seg_TP_res <- read.csv("~/EMH_Introgression_Project/Introgression_Detection/Revisions/Power_analysis_TP_TP_seg_sim.csv")
ACov_TP_res <- read.csv("~/EMH_Introgression_Project/Introgression_Detection/Revisions/Power_analysis_TP_TP_ACov_sim.csv")


THEME <-  theme_bw() + theme(axis.title=element_text(face="bold"))

folder_path_save <- "~/EMH_Introgression_Project/Introgression_Detection/Revisions_Figures_and_Data/"


Seg_SP_res_summary <- Seg_SP_res %>% group_by(sample,noise) %>% summarize(n_detected = sum(p > 0.05), n_reps = n() ) %>%
  mutate(proportion_detected = n_detected / n_reps) %>%
  dplyr::rename(ind = sample) %>% mutate(method = "Seg",sim = "SP")

ACov_SP_res_summary <- ACov_SP_res %>% group_by(ind,noise) %>% filter(covergence_TP == T) %>% summarize(n_detected = sum(p > 0.05), n_reps = n() ) %>%
  mutate(proportion_detected = n_detected / n_reps) %>% mutate(method = "ACov",sim = "SP")


Seg_TP_res_summary <- Seg_TP_res %>% group_by(sample,noise,alpha) %>% summarize(n_detected = sum(p < 0.05), n_reps = n() ) %>%
  mutate(proportion_detected = n_detected / n_reps) %>%
  dplyr::rename(ind = sample) %>% mutate(method = "Seg",sim = "TP")

ACov_TP_res_summary <- ACov_TP_res %>% group_by(ind,noise,alpha) %>% filter(covergence_TP == T) %>% summarize(n_detected = sum(p < 0.05), n_reps = n() ) %>%
  mutate(proportion_detected = n_detected / n_reps) %>% mutate(method = "ACov",sim = "TP")

Power_analysis_SP <- rbind(Seg_SP_res_summary,ACov_SP_res_summary) %>% mutate(ind = factor(ind, levels=c('Tianyuan', 'Salkhit')))
Power_analysis_TP <- rbind(Seg_TP_res_summary,ACov_TP_res_summary)  %>% mutate(ind = factor(ind, levels=c('Tianyuan', 'Salkhit')))

P_SP_power_analysis <- ggplot(Power_analysis_SP,aes(x=factor(as.character(noise), levels=c('0.001', '0.002', '0.004')),proportion_detected,fill=ind)) +
  facet_grid(~method) +
  geom_col(position = "dodge") +
  THEME +
  xlab("") +
  ylab("Proportion correctly detected") +
  ggtitle("Single pulse simulated")

P_TP_power_analysis <- ggplot(Power_analysis_TP,aes(x=factor(as.character(noise), levels=c('0.001', '0.002', '0.004')),proportion_detected,fill=ind)) +
  facet_grid(alpha~method) +
  geom_col(position = "dodge") +
  THEME +
  xlab("") +
  ylab("Proportion correctly detected") +
  ggtitle("Two pulses simulated")


P_power_analysis <- ggpubr::ggarrange(P_SP_power_analysis,P_TP_power_analysis,ncol = 2,
                                      labels = c("A","B"),common.legend = T,legend = "bottom")

ggsave(paste0(folder_path_save,"P_Power_analysis_TP_in_TY_SK.png"),P_power_analysis,device = "png",width = 8,height = 6)





#### Segment data

Slakhit_segments <- read.csv("/mnt/diversity/leonardo_iasi/EMH_Introgression_Project/New_REF_AA_with_APX_EMH_admixfrog0.7_Shared_Map/rle/error2/length_bin_15/5000/AFR-NEA-DEN/Shared_Map/SalkhitArchAdm_archaicadmixtureAPX.rle0.25.xz") %>%
  filter(type == "state", target == "NEA",map_len >= 0.2) %>% mutate(sample = "SalkhitArchAdm")
Tianyuan_segments <- read.csv("/mnt/diversity/leonardo_iasi/EMH_Introgression_Project/New_REF_AA_with_APX_EMH_admixfrog0.7_Shared_Map/rle/error2/length_bin_15/5000/AFR-NEA-DEN/Shared_Map/Tianyuan_archaicadmixtureAPX.rle0.25.xz") %>%
  filter(type == "state", target == "NEA",map_len >= 0.2) %>% mutate(sample = "Tianyuan")
Oase_segments <- read.csv("/mnt/diversity/leonardo_iasi/EMH_Introgression_Project/New_REF_AA_with_APX_EMH_admixfrog0.7_Shared_Map/rle/error2/length_bin_15/5000/AFR-NEA-DEN/Shared_Map/OaseNew_archaicadmixtureAPX.rle0.25.xz") %>%
  filter(type == "state", target == "NEA",map_len >= 0.2) %>% mutate(sample = "OaseNew")

AncientEAS <- rbind(Slakhit_segments,Tianyuan_segments,Oase_segments)

P_Salkhit_Tianyuan_100_longest_segments <- AncientEAS %>%
  filter(sample != "OaseNew") %>%
  group_by(sample) %>% 
  top_n(n = 100) %>%
  mutate(rank_length = rank(-(map_len),ties.method = "random")) %>%
  ggplot(.,aes(x =  map_len , y = log(rank_length), col = sample,shape=sample)) +
  geom_point(alpha= 0.7,size = 3) +
  THEME +
  #coord_cartesian(expand = F) +
  geom_smooth(method = lm) +
  xlab("Segment length in centMorgan") +
  ylab("segments ranked by size (log scaled)") +
  labs(col='Sample',shape='Sample')

ggsave(paste0(folder_path_save,"P_Salkhit_Tianyuan_100_longest_segments.png"),P_Salkhit_Tianyuan_100_longest_segments,device = "png",width = 8,height = 8)

samples = c("SalkhitArchAdm","Tianyuan","OaseNew")

AncientEAS_TP_Seg <- data.frame(sample = rep(NA,length(samples)),
                                tm1_TP = rep(NA,length(samples)),
                                tm2_TP = rep(NA,length(samples)),
                                alpha1_TP = rep(NA,length(samples)),
                                alpha2_TP = rep(NA,length(samples)),
                                n_TP = rep(NA,length(samples)),
                                tm_SP =rep(NA,length(samples)),
                                LL_TP = rep(NA,length(samples)),
                                LL_SP = rep(NA,length(samples)))
for(i in 1:length(samples)){
  l = AncientEAS$map_len[AncientEAS$sample == samples[i]]/100 - 0.002
  alpha1_hat <- 0.9
  t1_hat <- 100
  alpha2_hat <- 0.1
  t2_hat <- 50
  
  res_SS_TP <- Two_pulses_EM_SS(l,alpha1_hat,alpha2_hat,t1_hat,t2_hat,num_iterations=500)
  
  tm_SP = 1/mean(l)
  LL_SP = sum(log(dexp(l, tm_SP,log = F)))
  
  AncientEAS_TP_Seg[i,1] = samples[i]
  AncientEAS_TP_Seg[i,2] = res_SS_TP[3]
  AncientEAS_TP_Seg[i,3] = res_SS_TP[4]
  AncientEAS_TP_Seg[i,4] = res_SS_TP[1]
  AncientEAS_TP_Seg[i,5] = res_SS_TP[2]
  AncientEAS_TP_Seg[i,6] = length(l)
  AncientEAS_TP_Seg[i,7] = tm_SP
  AncientEAS_TP_Seg[i,8] = res_SS_TP[5]
  AncientEAS_TP_Seg[i,9] = LL_SP
}
res_check_TP_Seg <- AncientEAS_TP_Seg %>%
  mutate(LRT = -2 *((LL_SP - LL_TP))) %>%
  mutate(p  = 1 - pchisq(LRT, 3 - 1)) 

write.csv(res_check_TP_Seg,paste0(folder_path_save,"Testing_two_pulses_vs_one_Salkhit_Tianyuan_Segments.cvs"),quote = F,row.names = F)
```

### On real data

```{r eval=T,echo=F,results='hide'}
#### ACov data

min_l = 0.02
trunc_ = "estimated_truncation"
map_ = "Shared_Map"

MinFactor = 0.00004
MaxIter = 50

input_file_folder = paste0("/mnt/diversity/leonardo_iasi/EMH_Introgression_Project/EMH_dating_analysis/",map_,"_moorjani_et_al/")


ACov_list <- list()
for(i in 1:length(samples)){
  smpl = samples[i]
  if(smpl %in% c("BK1653","BKBB7240","BKF6620","BKCC7335","OaseNew","UstIshim","ZlatyKunShotgun")) {
    print("Sampling longer ACov")
    x <- read.table(paste0(input_file_folder,"longer_distance/outfiles_",smpl,"/",smpl))  
  } else{
    x <- read.table(paste0(input_file_folder,"outfiles_",smpl,"/",smpl))
  }
  if(trunc_ == "not_truncated"){
    max_l = 60
  }
  if(trunc_ == "estimated_truncation"){
    max_l = x$V1[which(x$V2 < 0)[1]]
    if(is.na(max_l)){
      max_l = 1
    }
    if( max_l < 1){
      max_l = 1
    }
    max_l = round_any(max_l,1, f = ceiling) 
  }
  if(trunc_ == "fixed_truncation"){
    if(smpl %in% c("BK1653","BKBB7240","BKF6620","BKCC7335","OaseNew","UstIshim","ZlatyKunShotgun")){
      max_l = truncation_df$trunc[truncation_df$sample == smpl]
    } else {
      max_l = 1
    }
  }
  
  x <- x %>% filter(V1 >= min_l, V1 <= max_l) %>% 
    dplyr::rename(dist = V1, wcov = V2) %>% mutate(dist = dist/100)
  
  ACov_list[[i]] <- x
}

Plot_Acov_data <- rbind(data.frame(dist = ACov_list[[1]][,1],wcov =  ACov_list[[1]][,2],sample = "SalkhitArchAdm"),
                        data.frame(dist = ACov_list[[2]][,1],wcov =  ACov_list[[2]][,2],sample = "Tianyuan"),
                        data.frame(dist = ACov_list[[3]][,1],wcov =  ACov_list[[3]][,2],sample = "OaseNew"))



AncientEAS_SP_ACov <- data.frame(sample = rep(NA,length(unique(samples))),
                                 tm_SP = rep(NA,length(unique(samples))),
                                 A_SP = rep(NA,length(unique(samples))),
                                 c_SP = rep(NA,length(unique(samples))),
                                 n_SP = rep(NA,length(unique(samples))),
                                 LL_SP = rep(NA,length(unique(samples))))

f_predict_SP_ACov <- list()
for(i in 1:length(unique(samples))){
  ind = unique(samples)[i]
  
  dist=ACov_list[[i]]$dist
  y=ACov_list[[i]]$wcov
  offset = 0
  A_init = 0.1
  C_init = 0.1
  tm_init = 200
  
  fm1 <- function(x) x[3] + x[1]*exp(-x[2] * dist)
  fm2 <- function(x) sum((y-fm1(x))^2)
  fm3 <- DEoptim(fm2, lower=c(0.0001,1,0.0001), upper=c(10,1000,10e7), control=list(trace=FALSE))
  par1 <- fm3$optim$bestmem
  
  # parameters for y ~ Ae-mt + C
  names(par1) <- c("A","tm","C")
  
  # fit the model of Single exponential
  res_fit <- nls(y ~ fnx_SP_singlefit(A,tm,C,0,dist), start=par1,algorithm="port",
                 lower=c(0,1,-1), upper=c(1,2000,1),
                 control=list(warnOnly=TRUE))
  
  RSS = sum((y - fnx_SP_singlefit(coef(res_fit)[1],coef(res_fit)[2],coef(res_fit)[3],0,dist))^2)
  n_DP = length(dist)
  LL = - n_DP/2 * log(RSS) - n_DP/2 * log(2*pi / n_DP) - n_DP/2
  AncientEAS_SP_ACov[i,1] = ind
  AncientEAS_SP_ACov[i,2] = coef(res_fit)[2]
  AncientEAS_SP_ACov[i,3] = coef(res_fit)[1]
  AncientEAS_SP_ACov[i,4] = coef(res_fit)[3]
  AncientEAS_SP_ACov[i,5] = length(dist)
  AncientEAS_SP_ACov[i,6] = LL
  
  f_predict_SP_ACov[[i]] = data.frame(dist_M = dist, ALD = predict(res_fit),sample = ind,model = "One_Pulse")
  
  
}
f_predict_SP_ACov <- do.call('rbind',f_predict_SP_ACov)


AncientEAS_TP_ACov <- data.frame(sample = rep(NA,length(unique(samples))),
                                 tm1_TP = rep(NA,length(unique(samples))),
                                 tm2_TP = rep(NA,length(unique(samples))),
                                 a1_TP = rep(NA,length(unique(samples))),
                                 a2_TP = rep(NA,length(unique(samples))),
                                 c_TP = rep(NA,length(unique(samples))),
                                 n_TP = rep(NA,length(unique(samples))),
                                 LL_TP = rep(NA,length(unique(samples))),
                                 convergence = rep(NA,length(unique(samples))))

f_predict_TP_ACov <- list()
for(i in 1:length(unique(samples))){
  ind = unique(samples)[i]
  
  dist=ACov_list[[i]]$dist
  y=ACov_list[[i]]$wcov
  offset = 0
  A1_init = 0.1
  A2_init = 0.01
  C_init = 1
  tm1_init = 450
  tm2_init = 300
  
  
  fm1 <- function(x) x[5] + (x[1]*exp(-x[3] * dist) + x[2]*exp(-x[4] * dist))
  fm2 <- function(x) sum((y-fm1(x))^2)
  fm3 <- DEoptim(fm2, lower=c(0.1,0.0001,1,1,0.0001), upper=c(10,10,2000,2000,10e7), control=list(trace=FALSE))
  par1 <- fm3$optim$bestmem
  
  # parameters for y ~ Ae-mt + C
  names(par1) <- c("A1","A2","tm1","tm2","C")
  
  res_fit <- nls(y ~ fnx_TP_singlefit(A1,A2,tm1,tm2,C,0,dist), start=par1, algorithm="port",
                 lower=c(0,0,1,1,-1), upper=c(1,1,2000,2000,1),
                 control=list(warnOnly=TRUE))
  
  
  
  RSS = sum((y - fnx_TP_singlefit(coef(res_fit)[1],coef(res_fit)[2],coef(res_fit)[3],coef(res_fit)[4],coef(res_fit)[5],0,dist))^2)
  n_DP = length(dist)
  LL = - n_DP/2 * log(RSS) - n_DP/2 * log(2*pi / n_DP) - n_DP/2
  AncientEAS_TP_ACov[i,1] = ind
  AncientEAS_TP_ACov[i,2] = coef(res_fit)[3]
  AncientEAS_TP_ACov[i,3] = coef(res_fit)[4]
  AncientEAS_TP_ACov[i,4] = coef(res_fit)[1]
  AncientEAS_TP_ACov[i,5] = coef(res_fit)[2]
  AncientEAS_TP_ACov[i,6] = coef(res_fit)[5]
  AncientEAS_TP_ACov[i,7] = length(dist)
  AncientEAS_TP_ACov[i,8] = LL
  AncientEAS_TP_ACov[i,9] = res_fit$convInfo$isConv
  
  f_predict_TP_ACov[[i]] = data.frame(dist_M = dist, ALD = predict(res_fit),sample = ind,model = "Two_Pulses")
  

}
f_predict_TP_ACov <- do.call('rbind',f_predict_TP_ACov)

res_check_TP_ACov <- inner_join(AncientEAS_SP_ACov,AncientEAS_TP_ACov) %>%
  mutate(tm_SP_lower = matrix(Get_CI_Dating_fn(tm_SP,n_SP),ncol=3)[,2],
         tm_SP_upper = matrix(Get_CI_Dating_fn(tm_SP,n_SP),ncol=3)[,3],
         tm1_TP_lower = matrix(Get_CI_Dating_fn(tm1_TP,n_SP),ncol=3)[,2],
         tm1_TP_upper = matrix(Get_CI_Dating_fn(tm1_TP,n_SP),ncol=3)[,3],
         tm2_TP_lower = matrix(Get_CI_Dating_fn(tm2_TP,n_SP),ncol=3)[,2],
         tm2_TP_upper = matrix(Get_CI_Dating_fn(tm2_TP,n_SP),ncol=3)[,3]) %>%
  mutate(LRT = -2 *((LL_SP - LL_TP))) %>%
  mutate(p  = 1 - pchisq(LRT, 5 - 3)) 

write.csv(res_check_TP_ACov,paste0(folder_path_save,"Testing_two_pulses_vs_one_Salkhit_Tianyuan_ACov.cvs"),quote = F,row.names = F)

predict_ACov <- rbind(f_predict_SP_ACov,f_predict_TP_ACov)


P_Salkhit_Tianyuan_ACov = ggplot(Plot_Acov_data,aes(x = dist * 100,y = (wcov),col = sample)) +
  facet_grid(~sample,scales = "free_x") +
  geom_point() +
  geom_line(data = predict_ACov,aes(x=dist_M*100,y=ALD,linetype=model),size=1.2,col="black") +
  xlab("Distance (cM)") +
  ylab("Ancestry covariance") +
  THEME 

ggsave(paste0(folder_path_save,"P_Salkhit_Tianyuan_ACov.png"),P_Salkhit_Tianyuan_ACov,device = "png",width = 12,height = 8)
```
