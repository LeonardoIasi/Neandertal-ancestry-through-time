import pysam
import csv
from pybedtools import BedTool
import csv
import pybedtools
import pandas as pd

def _prepare_bam_filter(wc):
    bam_path = config["EMH"][wc.sample]["bam"]
    s = "{}".format(bam_path)
    return s


def bed_from_anno_seg_file(input_file,filter_map_len,filter_target,filter_type):
    df = pd.read_csv(input_file)

    filtered_df = df[(df['map_len'] >= filter_map_len) & (df['target'].isin(filter_target)) & (df['type'].isin(filter_type) )]
    selected_columns = ['chrom', 'pos', 'pos_end', 'frag_ID']
    filtered_df = filtered_df[selected_columns]

   # sorted_df = filtered_df.sort_values(by=['chrom', 'pos'], key=lambda x: x.apply(lambda y: int(y.strip('chrX'))))

    bedtool_obj = pybedtools.BedTool.from_dataframe(filtered_df, sep='\t')
    return bedtool_obj

def bed_from_diagnostic_sites_file(input_file):
    df = pd.read_csv(input_file,sep= ' ')
    df1 = df.iloc[:, 0:2]

    df1.columns =['chrom', 'end']
    df1['start'] = df1['end'] -1
    df1 = df1[["chrom","start","end"]]

    bedtool_obj = pybedtools.BedTool.from_dataframe(df1, sep='\t')
    return bedtool_obj


def intersect_bed_files(positions_bed_file_object, intervals_bed_file_object):
    # Load BED files using pybedtools
    positions_bed = positions_bed_file_object
    intervals_bed = intervals_bed_file_object

    # Perform intersection and retain positions from the first BED file
    intersected_bed = positions_bed.intersect(intervals_bed, wa=True, wb=True)

    # Write the intersection results to the output BED file
    return intersected_bed

def has_deamination(read):
    refseq = read.get_reference_sequence()
    if read.is_reverse:
        for r, q in zip(refseq[:3], read.query[:3] ):
            if r == 'g' and q == 'A':
                return True
        for r, q in zip(refseq[-3:], read.query[-3:] ):
            if r == 'g' and q == 'A':
                return True
    else:
        for r, q in zip(refseq[:3], read.query[:3] ):
            if r == 'c' and q == 'T':
                return True
        for r, q in zip(refseq[-3:], read.query[-3:] ):
            if r == 'c' and q == 'T':
                return True
    return False


rule get_diagnostic_pileup:
    input:
        input_anno_segment_file = "{Folder_name}/rle/{admf_params}/length_bin_{length_bin}/{bin_size}/{states}/{map}/{sample}_{snpset}.rle{penalty}.xz.anno_all_types",
        input_file_diagnostic_sites = "/Phylogenetic_fragment_analysis/informative_sites_Mbuti_Vi33.19_Altai_Chagyrskaya_Den3_chrom21.tab",
        bam_file= _prepare_bam_filter,
        #bam_index= "{input.bam_file}" + ".bai"
    params:
        filter_map_len = 0.2,
        filter_target = ['NEA',"DEN"],
        filter_type = ['state'],
        min_read_length = 35,
        min_mapping_quality = 25,
        filter_deam = False
        #filter_deam = True
    output:
        diagnostic_pileup_file = "{Folder_name}/Diagnostic_sites/{admf_params}/length_bin_{length_bin}/{bin_size}/{states}/{map}/allSites/{sample}_{snpset}.rle{penalty}.tab",
    run:

        bed_file_segments = bed_from_anno_seg_file(input.input_anno_segment_file,float(params.filter_map_len),params.filter_target,params.filter_type)

        bed_file_diagnostic_sites = bed_from_diagnostic_sites_file(input.input_file_diagnostic_sites)

        bed_reader = intersect_bed_files(bed_file_diagnostic_sites,bed_file_segments)

        # Open the BAM file
        bam = pysam.AlignmentFile(input.bam_file, "rb")

        # Create a dictionary to store the counts for each position
        counts = {}

        # Iterate over each region in the BED file
        for row in bed_reader:
            chrom = row[0]
            pos_start = int(row[1])
            pos_end = int(row[2])
            identifier = row[6]

            # Initialize nucleotide counts for the region
            count_a = 0
            count_c = 0
            count_g = 0
            count_t = 0

            # Iterate over reads overlapping the region
            for alignment in bam.fetch(chrom, pos_start, pos_end):
                if params.filter_deam:
                    if 'MD' not in alignment.tags:
                                continue
                    if not has_deamination(alignment):
                        continue
                # Filter out reads based on minimum length
                if alignment.query_length >= float(params.min_read_length):
                    # Filter out reads based on minimum mapping quality
                    if alignment.mapping_quality >= int(params.min_mapping_quality):

                        # Get the alignment start and end positions
                        alignment_start = alignment.reference_start
                        alignment_end = alignment.reference_end

                        # Determine the overlapping region
                        overlap_start = max(pos_start, alignment_start)
                        overlap_end = min(pos_end, alignment_end)

                        # Iterate over the bases in the overlapping region
                        for pos in range(overlap_start, overlap_end):
                            query_pos = alignment.query_alignment_start + pos - alignment_start

                            # Check if the query position is within a valid range
                            if query_pos < 0 or query_pos >= len(alignment.query_sequence):
                                continue

                            # Get the nucleotide at the query position
                            nucleotide = alignment.query_sequence[query_pos]

                            # Update the corresponding nucleotide count
                            if nucleotide == 'A':
                                count_a += 1
                            elif nucleotide == 'C':
                                count_c += 1
                            elif nucleotide == 'G':
                                count_g += 1
                            elif nucleotide == 'T':
                                count_t += 1

            # Store the nucleotide counts for the position
            counts[(chrom, pos_start, pos_end, identifier)] = (count_a, count_c, count_g, count_t)

        # Write the output table
        with open(output.diagnostic_pileup_file, "w") as file:
            writer = csv.writer(file, delimiter="\t")
            writer.writerow(["chrom", "pos start", "pos end", "ID", "A", "C", "G", "T"])
            for (chrom, pos_start, pos_end, identifier), nucleotide_counts in counts.items():
                writer.writerow([chrom, pos_start, pos_end, identifier] + list(nucleotide_counts))

        # Close the BAM file
        bam.close()


rule match_diagnostic_pileup:
    input:
        input_anno_segment_file = "{Folder_name}/rle/{admf_params}/length_bin_{length_bin}/{bin_size}/{states}/{map}/{sample}_{snpset}.rle{penalty}.xz.anno_all_types",
        diagnostic_pileup_file = "{Folder_name}/Diagnostic_sites/{admf_params}/length_bin_{length_bin}/{bin_size}/{states}/{map}/allSites/{sample}_{snpset}.rle{penalty}.tab",
        diagnostic_ref = "Phylogenetic_fragment_analysis/informative_sites_Mbuti_Vi33.19_Altai_Chagyrskaya_Den3_annotated_chrom21.tab",
        bed_file = "admixfrogREF/bed/{snpset}.bed"
    params:
        filter_map_len = 0.2,
        n_bootstrap = 100,
        filter_target = ['NEA',"DEN"],
        filter_type = ['state']
    output:
        diagnostic_match_file_raw = "{Folder_name}/Diagnostic_sites/{admf_params}/length_bin_{length_bin}/{bin_size}/{states}/{map}/{DiagSites}/{sample}_{snpset}.rle{penalty}.match.xz",
        diagnostic_match_file_sum = "{Folder_name}/Diagnostic_sites/{admf_params}/length_bin_{length_bin}/{bin_size}/{states}/{map}/{DiagSites}/{sample}_{snpset}.rle{penalty}.match_summary.xz",
        diagnostic_match_file_sum_TS_only = "{Folder_name}/Diagnostic_sites/{admf_params}/length_bin_{length_bin}/{bin_size}/{states}/{map}/{DiagSites}/{sample}_{snpset}.rle{penalty}.match_summary_transversions_only.xz",
    script:
        "Phylogenetic_fragment_analysis/Diagnostic_matching.R"
